# 알고리즘 기말정리

목차 : 

- [1. dp알고리즘](#5장---동적-계획-알고리즘-dynamic-programming)
- [2. 정렬 알고리즘](#6장-정렬-알고리즘)
- [3. 근사 알고리즘](#8장-근사-알고리즘)
---


## 5장 - 동적 계획 알고리즘 (Dynamic Programming)

- 입력 크기가 작은 부분 문제들을 모두 해결하여 저장한 다음, 그 해들을 이용하여 큰 문제를 해결해 나가는 방법.
- 기억하며 풀기 라고도 불림.
- 최적 부분 구조로 이루어져 있는 문제에 적합.<br/>
최적 부분 구조 &rarr; **문제의 최적 해결 방법은 부분 문제의 최적 해결 방법과 같다**.
- 분할 정복과 비슷하면서 다른데 분할정복은 기본적으로 top-down, 동적 계획 방법은 기본적으로  bottom-up의 형태를 띔.<br/>
bottom-up의 예시 : 피보나치 수열 알고리즘.<br/>
top-down의 예시 : 퀵정렬 등.
- 동적 계획 방법은 작은 문제에 대한 모든 가능성을 고려하기 때문에 다음 크기의 문제에 대한 최적해를 구할 수 있다<br/>
&rarr; 항상 최적해를 구할 수 있다.
- 동적 프로그래밍을 적용 단계
    1. 문제의 특성을 분석하여 최적성의 원리가 성립되는지 확인. &rarr; 이 문제에 동적 계획 알고리즘을 적용할 수 있나?
    2. 주어진 문제에 대해 최적해를 제공하는 점화식을 도출. &rarr; 작은 문제를 이용하여 다음 크기의 문제에 대한 최적해를 구할 수 있는 점화식을 찾음.
    3. 가장 작은 부분 문제부터 점화식의 해를 구한 뒤 테이블에 저장. &rarr; 점화식을 이용하여 dp 테이블을 채워감.
    4. 테이블에 저장되어있는 부분 문제의 해를 이용하여 상위 문제의 해를 구함. &rarr; 내가 원하는 크기의 답을 구한다.

### 1. 모든 쌍 최단 경로 문제.

- 여러 지점이 있을 때 각 쌍의 점 사이의 최단 경로를 찾는 문제.

- 각 점을 시작점으로 정하여 다익스트라 알고리즘을 수행하는 방법.<br/>
    - 시간복잡도 : $(n-1)O(n^2)$<br/>
    - &rarr; n-1 : (n-1)개의 점들에 대해 다익스트라 알고리즘을 수행함.<br/>
    - &rarr; $O(n^2)$ : 다익스트라 알고리즘 시간복잡도<br/>
    - 다익스트라 알고리즘 : 시점에 대해 각 점까지의 최단거리를 구하는 알고리즘.

- **플로이드-워셜 알고리즘(dp)을 이용한 방법.**<br/>
    - 두 정점을 잇는 최소 비용 경로는 경유지를 거치거나 거치지 않는 경로 중 하나다.
    - 만약 경유지를 거친다면 그것을 이루는 경로 역시 최소 비용 경로이다.
    - All Pairs Shortest에서는 음수 사이클이 없어야 한다.<br/>
    &rarr; 음수사이클이 있다면 그 사이클을 돌 때마다 거리가 짧아지기 때문에. -∞가 됨.
    - 시간복잡도는 $O(n^3)$. 

    1. $D^k_{ij}$ = 점 {1,~k}만을 경유 가능한 점으로 고려하여 i ~ j까지 경로중 가장 짧은 거리.
    <br/> 즉, $D^0_{ij}$는 선분(i,j)의 가중치이다.
    2. 그렇기 때문에 $D^1_{ij}$는 i &rarr; j로 가는 경로 중 1을 경유하는 최소 거리를 의미한다.
    <br/> 즉, $D^1_{ij} = min(D^0_{i1} + D^0_{1j}, D^0_{ij})$가 된다.
    3. 따라서 모든 쌍 i, j에 대해서 $D^1_{ij}$를 계산하는 것이 가장 작은 부분문제이다.
    4. 그 다음엔 점 2를 경유해서 i &rarr; j로 가는 경로의 거리와 $D^1_{ij}$ 중 더 짧은 거리가 $D^2_{ij}$가 된다.<br/>
    즉, $D^2_{ij} = min(D^1_{i2} + D^1_{2j}, D^1_{ij})$ 이고, <br/>
    $D^1_{i2}$와 $D^1_{2j}$는 이미 전 단계에 구해놓았다.
    5. 이렇게 경유하는 점을 바꿔가며 총 n번 반복하게 되면 모든 점의 쌍에 대한 최단거리가 정해지게 된다.

- 플로이드 워셜 추가 설명
    1. 2차원 dp테이블을 형성한다. dp[][]
    2. 입력으로 받은 각 점들사이에 선분이 있다면 그 가중치를 dp[1][2] = 2 와 같이 $D^0_{ij}$들을 갱신한다.
    3. $D^1_{ij} = min(D^0_{i1} + D^0_{1j}, D^0_{ij})$ 이것을 이용해서 $D^1_{ij}$ 로 바뀐 값들을 dp테이블에서 갱신함.
    4. 위의 방법을 n번 반복.

### 2. 연속된 행렬 곱셈.
- 행렬을 세개 이상 연속해서 곱하는 경우 결합 법칙이 성립하므로 어떤 순서로 곱하는지에 따라 곱셈 연산의 횟수가 달라진다.
- 가장 적게 곱셈 연산을 수행하는 경우를 찾는 dp문제.
- 행렬 곱셈이 최적부분구조를 갖나?<br/>
&rarr; $M_1(M_2((M_3M_4)M_5))$라면 $M_3M_4M_5$의 최적 순서는 무조건 $(M_3M_4)M_5$일 수밖에 없다.<br/> &rarr; 부분최적 구조를 갖는다.

- 해결 방법.<br/>
    $M_1(10, 5), M_2(5, 20), M_3(20, 4), M_4(4, 30)$ 인 경우.
    1. 각 행렬들의 열들을 C[i]에 저장하고, C[0]에는 $M_1$의 행의 개수를 넣음. <br/>

        | k | 0  | 1 | 2  | 3 | 4  |
        |---|----|---|----|---|----|
        | C | 10 | 5 | 20 | 4 | 30 | 
    
    - C[k] : 행렬 열의 수.

    2. 행렬의 i ~ j사이의 최소 연산 횟수를 저장하기 위한 dp 테이블 (2차원 배열)과 묶인 괄호의 위치를 저장할 2차원 테이블을 만듦.

    3. i 와 j가 같다면 곱연산을 수행하지 않으므로 i == j인 대각선에 모두 0을 넣음.

    4. i = j-1인 대각선을 채워넣는다.<br/>
    S[i][j] = S[i][k] + S[K+1][j] + C[i-1]*C[k]*C[j] 들 중 최솟값이 된다.

    5. 위의 공식을 이용하여 모든 dp 테이블을 채운다.

    6. 위의 예제를 보면
        - 3번까지의 진행 상황이 다음과 같다.<br/>

            | s[ ][ ] | 1 | 2 | 3 | 4 |
            |----|----|----|----|----|
            |1  |0  |   |   |   |
            |2  |   | 0 |   |   |
            |3  |   |   | 0 |   |
            |4  |   |   |   |  0|

        - 4번을 1번 수행한 결과 : <br/>
        S[1][2] = $min_{(1<= k <= 1)} (S[1][k] + S[k+1][2] + C[0]*C[k]*C[2])$ <br/>
         = $min(S[1][1] + S[2][2] + C[0]*C[1]*C[2])$<br/>
         = $min(0 + 0 + 10 * 5 * 20)$ <br/>
         = 1000. <br/>

            S[2][3] = 400<br/>
            S[3][4] = 2400<br/>

            | s[ ][ ] | 1 | 2 | 3 | 4 |
            |----|----|----|----|----|
            |1  |0  |1000|   |   |
            |2  |   | 0 |400|   |
            |3  |   |   | 0 |2400|
            |4  |   |   |   |  0|
        
            T[1][2] = 1
            T[2][3] = 2
            T[3][4] = 3
        - 4번을 2번 수행한 결과 : <br/>
        S[1][3] = $min_{(1<=k<=2)} (S[1][k] + S[k+1][3] + C[0]*C[k]*C[3])$ : $M_1(M_2M_3) or (M_1M_2)M_3$인 경우.<br/>
        = 600

            S[2][4] = 1000<br/>

            | s[ ][ ] | 1 | 2 | 3 | 4 |
            |----|----|----|----|----|
            |1  |0  |1000|600|   |
            |2  |   | 0 |400|1000|
            |3  |   |   | 0 |2400|
            |4  |   |   |   |  0|

            T[1][3] = 1
            T[2][4] = 3 : (M2M3)M4라는 뜻. 앞에서부터 (2) ~ 3번까지 묶음.

        - 4번을 3번 수행한 결과 : <br/>
        S[1][4] = $min_{(1<=k<=3)}(S[1][k] + S[k+1][4] + C[0]*C[k]*C[4])$<br/>
        k = 1이라면 $M_1(M_2M_3M_4)$ 인경우. = 2500<br/>
        k = 2이라면 $M_1M_2(M_3M_4)$ 인경우. = 9400<br/>
        k = 3이라면 $(M_1M_2M_3)M_4$ 인경우. = 1800<br/>

            | s[ ][ ] | 1 | 2 | 3 | 4 |
            |----|----|----|----|----|
            |1  |0  |1000|600|1800|
            |2  |   | 0 |400|1000|
            |3  |   |   | 0 |2400|
            |4  |   |   |   |  0|

            T[1][4] = 1

- 시간 복잡도 :<br/> 
대각선 수(d)를 n-1번 반복. O(n). <br/>
한 대각선 당 대각선 원소의 수 n-d번 반복, S[i][j]에서 (i, j)가 포함된 대각선의 원소의 개수 n - d, d = j - i, O(n).<br/>
마지막에 각 원소들의 값을 구해줄 때 i <= k <= j-1 인 k들에 대하여 최솟값을 구했다. 즉, O(j-i-1) == O(j-i) == O(d).<br/>
총 시간 복잡도 : <br/>
$\sum_{d=1}^{n-1} \sum^{n-d}_{i=1}(j-i)$ <br/><br/>
= $\sum_{d=1}^{n-1} \sum_{i=1}^{n-d}d$ <br/><br/>
= $\sum_{d=1}^{n-1}(nd - d^2)$ <br/><br/>
= $n\sum_{d=1}^{n-1}d - \sum_{d=1}^{n-1}d^2$ <br/><br/>
= $\frac{n^2(n-1)}{2} - \frac{(n-1)n(2n-1)}{6} = \frac{n^3-n}{6} = \theta(n^3)$.

### 3. 편집 거리 문제
- 문자열 S를 T로 변환시키는데 필요한 편집 연산 횟수를 구하는 알고리즘.

- 연산은 삽입, 제거, 대체의 3개가 있다.

- 부분 문제의 정의 : E[i, j] : S의 접두부의 i개 문자를 T의 접두부 j개 문자로 변환시키는 데 필요한 최소 연산 횟수.

- 부분문제 E[4, 3]을 알기 위해서는 E[4,2], E[3, 3], E[3, 2]를 알아야 한다. <br/>
E[4,3] == E[4,2] + 1(삽입) == E[3, 3] + 1(삭제) == E[3, 2] + 1(대체 or 유지.)

- 편집 거리 문제를 해결하는 방법
    1. E[i, 0], E[0, j]를 모두 채운다.<br/>

        |S/T | 0 | 1 | 2 | 3 | 4 |
        |--- | --- | --- | --- | --- | --- |
        | 0 | 0 | 1 | 2 | 3 | 4 |
        | 1 | 1 |  |  |  |  |
        | 2 | 2 |  |  |  |  |
        | 3 | 3 |  |  |  |  |
        | 4 | 4 |  |  |  |  |

        E[i, 0]은 모두 i이기 때문에, i번 삭제 or 삽입.

    2. 채워진 dp테이블을 가지고 E[i, j]를 차례대로 계산한다.

    3. E[i, j] = min(E[i, i-1] + 1, E[i-1, j] + 1, E[i-1, j-1] + a)<br/>
    a : 다음에 올 문자가 같다면 0, 다르다면 1.
    
- 시간 복잡도 : <br/>
    이 문제의 시간 복잡도는 $O(nm)$이다. <br/>
    m 과 n은 각 문자열의 길이인데 그 이유는 m x n배열을 하나씩 채워야 하고, <br/>
    세 가지의 최솟값을 구하는 시간은 상수 시간이 걸리기 때문이다.

### 4. 배낭 문제
- n개의 물건과 각 물건 i의 무게 $w_i$와 가치 $v_i$가 주어진다.<br/>
    배낭의 용량은 C일 때 배낭에 담을 수 있는 물건의 최대 가치를 찾는 문제.<br/>
    단, 물건은 하나씩만 넣을 수 있다.

- 부분 문제의 정의<br/>
    K[2, 10]은 물건 1과 2를 고려했을 때 10kg의 용량을 높은 가치로 채울 수 있는 최대.<br/>
    그렇기 때문에 K[1, 0:10]을 부터 채우며 이를 이용하여 다음 물건을 최대 가치로 채울 수 있게 됨.

- 해결 방법 : <br/>
    | 무게 | 가치 | 물건 | w=0  | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 |
    |------|------|------|----|----|----|----|----|----|----|----|----|----|----|
    | 0    | 0    | -    | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 0  | 0  |
    | 5    | 10   | i=1  | 0  | 0  | 0  | 0  | 0  | 10 | 10 | 10 | 10 | 10 | 10 |
    | 4    | 40   | i=2  | 0  | 0  | 0  | 0  | 40 | 40 | 40 | 40 | 40 | 50 | 50 |
    | 6    | 30   | i=3  | 0  | 0  | 0  | 0  | 40 | 40 | 40 | 40 | 40 | 50 | 70 |
    | 3    | 50   | i=4  | 0  | 0  | 0  | 50  | 50 | 50 | 50 | 90 | 90 | 90 | 90 |

    1. 가방의 용량을 0 ~ 최대 용량 까지 늘려가며 물건을 하나씩 비교함.
    
    2. 물건 1을 가방 용량에 대하여 최대 가치를 만드는 표를 작성함.

    3. 물건 2를 포함하여 해당 무게에서 최대 가치를 만드는 점화식<br/>
    max(K[i-1, $w$], K[i-1, $w$ - $w_i$] + $v_i$) 을 만족하는 K[i, w]을 채워간다.<br/>
    &rarr; 물건 2를 고려하는데, 이 물건을 넣지 않았을 때 vs 이 물건을 넣고, (현재무게 - 물건 2의 무게)때의 최대 가치 중 큰 값을 선택함.

- 시간 복잡도 : <br/>
dp테이블이 2차원 &rarr; n(물건의수) x C(가방 용량)으로 채워지기 때문에 O(nC)가 된다.

### 5. 동전 거스름돈 문제.
- 최대한 적은수의 동전으로 잔돈을 거슬러주는 알고리즘.

- 부분문제 정의: <br/>
동전의 종류가 4가지 (1, 5, 10, 50)원일 때 n원을 거슬러 준다면 <br/>
C[n] = max(C[n-1] + 1(1원), C[n-5] + 1(5원), C[n-10] + 1(10원), C[n-100] + 1(100원))이 될 것이다.
<br/>
그러므로 C[0]만 정의해줘도 [n - 100]의 경우를 예외처리만 해주어도 계산할 수 있다.

- 해결 방법 : <br/>
    1. dp테이블 1차원 배열 정의.
    2. C[0] = 0. (0원을 거슬러 주는 개수는 0)
    3. C[n] = max(C[n-1] + 1, C[n-5] + 1, C[n-10] + 1, C[n-100] + 1) 을 통해 dp테이블을 채워 넣는다.

- 시간 복잡도 : <br/>
    O(nk) : n원의 거스름돈, k개의 동전 종류.<br/>
    하나의 dp테이블 원소를 채우기 위해 동전의 개수만큼의 연산이 필요하다.

---

## 6장 정렬 알고리즘.

### 1. 데이터를 정렬해야 하는 이유
- 사람은 소수의 데이터만을 다룰 수 있지만 컴퓨터가 다뤄야 할 데이터는 데이터베이스에선 이론상 무한개에 가깝다.
- 데이터를 다루기 위해서는 정렬이 필요하다.

### 2. 내부 정렬과 외부 정렬.
- 내부 정렬 : 입력의 크기가 주기억 장치의 공간보다 크지 않은 경우에 수행되는 정렬. <br/>
기본 내부 정렬 : 버블, 선택, 삽입 정렬. <br/>
효율적인 내부정렬 : 합병정렬, 퀵정렬, 힙정렬, 쉘정렬, 기수정렬 등.

- 외부 정렬 : 입력의 크기가 주기억 장치 공간보다 큰 경우, 보조기억 장치에 데이터를 저장하여 정렬을 함.<br/>
보조기억 장치에 있는 입력을 여러 번에 나누어 주기억장치에 읽어들인 후 합병정렬하여 보조기억 장치에 다시 저장함. <br/>
다방향 합병(p-way Merge), 다단계 합병(Polyphase Merge)가 대표적임.

### 3. 버블 정렬.
- 초등학생이나 생각할 만한 제일 기초적인 정렬.
- 이웃하는 숫자들을 비교하여 작은수를 앞으로 이동시키는 과정을 반복.
- 형태 :
    ``` cpp
    for pass = 1 to n-1:
        for i = 1 to n-pass:
            if(A[i-1] > A[i]):
                swap(A[i-1], A[i])
    ```
    pass를 한번 돌 때 마다 가장 큰 수가 정해진다.
- 시간복잡도 : $O(n^2)$.

### 4. 선택 정렬.
- 입력 배열 전체에서 최솟값을 '선택' 하여 배열의 0번 자리와 바꾸고,<br/>
나머지 원소에서 최솟값을 선택하여 1번과 바꾸고,<br/>
이를 반복.
- 형태 : 
```cpp
for i = 0 to n-2{
    min = i
    for j = i+1 to n-1 {
        if A[j] < A[min]
            min = j
    }
    swap(A[i], A[min])
}
```
외부 루프를 돌 때마다 가장 작은 수가 정해진다.
- 시간복잡도 : $O(n^2)$

### 5. 삽입 정렬.

- 삽입 정렬은 배열을 정렬된 앞부분과 정렬이 안 된 뒷부분으로 나누어서 정렬 안된 부분의 가장 왼쪽 원소를 정렬된 부분의 적절한 위치에 삽입해서 정렬하는 방법.

- 시작은 정렬된 부분 1개, 정렬 안 된 부분 n-1개.
- 정렬 안 된 부분의 맨 왼쪽을 정렬 된 부분의 원소를 하나씩 비교하며 들어갈 자리를 찾는다.
- 이를 n-1번 반복하면 끝.

- pseudo code
```cpp
for i to n-1
    currentElement = A[i]
    swap(A[j], A[j-1])
    while(j>=0 and A[j] > currnetelement)
    {
        A[j+1] = A[j]
        j--
    }
    swap(A[j+1], currentElement)
```

- 시간복잡도 : <br/>
외부 루프 : n-1번 반복.<br/>
내부 루프 : 최대 n-1번 반복.<br/>
평균, 최악 &rarr; $O(n^2)$<br/>
최선 &rarr; $O(n)$

### 6. 쉘 정렬.
- 아이디어
    1. 배열 뒷부분의 작은 숫자는 앞으로 빠르게 이동시키고.
    2. 앞부분의 큰 숫자는 뒤로 빠르게 이동시키고.
    3. 마지막에는 삽입정렬을 하는 알고리즘.<br/>
위의 두 과정을 통해 삽입정렬을 최선에 가까운 시간이 걸리게 된다.

- 방법.
    1. gap을 설정하여 (ex 5.) 5개의 간격으로 그룹을 만든다.<br/>
    15개의 원소가 있는 배열이었다면 3개씩 5개의 그룹이 만들어 질 것이다.
    2. 각 그룹별로 삽입 정렬을 수행한다.<br/>
    그러면 대충은 큰게 뒤로, 작은게 앞으로 와질 것이다.
    3. 그 다음에는 간격을 더 줄여서 (ex 3) 다시 삽입정렬을 수행한다.
    4. 점점 더 줄이다가 간격 1로 삽입정렬을 수행한다.
    <br/> 삽입정렬은 이미 정렬된 배열에 대해서는 O(n)의 최선 시간복잡도가 나타난다.

- pseudo-code
```cpp
for each gap h = (h0 > h1 > h2 > ... > h_k = 1){
    for i = h to n-1{ 
        // 앞의 h-1개의 원소는 삽입정렬을 수행할 때 정렬된 부분의 원소이기 때문에.
        CurrentElement = A[i];
        j = i
        while(j >= h and A[j-h] > CurrentElement){
            // j < h라면 맨 앞의 원소인 것이므로 continue;
            // 아니라면 j가 정렬되지 않은 부분의 원소이므로 
            // 앞의 원소들과 비교하여 삽입정렬을 수행함.
            swap(A[j], A[j-h])
            j = j-h
        }
        A[j] = CurrentElement
    }
}
```

- 시간 복잡도 : <br/>
최악 &rarr; $O(n^2)$<br/>
최선, 평균 : 밝혀지진 않았지만 $O(n^{1.25})$라고 한다.

### 7. 힙 정렬.
- 힙정렬이란 ? 
    - 힙 조건을 만족하는 완전 이진트리를 이용한 정렬.
    - 힙이란? <br/>
    각 노드의 값이 자식 노드의 값보다 큰 완전 이진 트리.<br/>
    그렇기 때문에 힙의 루트에는 항상 가장 큰 값이 저장된다.

- 힙정렬을 수행하는 과정
    1. 힙의 루트에는 가장 큰 값이 저장되므로 힙의 루트를 가장 마지막 노드의 수와 바꾼다.
    2. 힙조건에 위배되지않도록 다시 힙을 재구성해주고, 힙 크기를 1 줄인다.
    3. 이 과정을 반복한다.

- HeapSort pseudo-code
```cpp
배열 A에 대해 힙 자료구조를 만듦.
heapSize = n
for i = 1 to n-1{
    swap(A[1], A[heapSize])
    heapSize--; 
    // 사이즈를 줄여야 마지막 원소를 다시 찾을 때 
    // 중복되지 않는다.
    DownHeap() // 힙 구조를 재구성해줌.
}
```
- 시간복잡도 : <br/>
힙을 만드는 시간 : $O(n)$<br/>
변수를 초기화 하는 시간 : $O(1)$<br/>
가장 큰 값을 하나씩 결정하므로 외부 루프는 n-1번 반복됨 : $O(n)$<br/>
DownHeap을 수행하는 시간 : 힙의 높이에 비례 : $O(log n)$ <br/>
&rarr; $O(nlogn)$

### 9. 정렬 문제의 하한.
- 결정 문제의 하한이란?
    - n개의 서로 다른 숫자가 정렬되는 모든 경우의 수는 $n!$이다.
    - 이를 결정 트리에 넣어보면 이파리의 개수가 경우의 수다.
    - k개의 이파리가 있는 이진트리의 높이는 $log k$보다 크다.
    - 그러므로 n개의 서로 다른 숫자가 있는 결정 트리의 높이는 $log(n!)$보다 크다.
    - $log(n!) < O(n^n) = O(nlogn)$이므로 <br/>
    $O(nlogn)$보다 빠른 정렬 알고리즘은 있을 수 없다.

### 10. 기수 정렬.
- 기수정렬이란? 
    - 데이터 끼리 직접적인 비교하지 않고, 숫자를 부분적으로 비교한다.
    - 낮은 자릿수부터 자릿수 별로 비교한다.
    - 어느 비교정렬 알고리즘보다 빠르다.

- 기수정렬 기본 아이디어
    - 최대 자릿수가 100의 자릿수일 때
        1. 100의 자릿수로 정렬한다.
        2. 같은 100의 자릿수라면 순서를 유지하면서 10의자릿수로 비교함.
        <br/> stable_sort()를 생각.
        3. 이를 1의자릿수까지 반복.

- 시간 복잡도 : <br/>
k개의 자릿수가 있고, n개의 데이터가 있고, r진수의 숫자라고 한다면<br/>
각 자릿수에 대해서 n개의 데이터를 비교하고, r개로 분류하기 때문에<br/>
$(n+r) \times k$의 시간이 걸림.

### 11. 외부 정렬.
- 입력 크기가 매우 커서 주기억 장치에서는 다룰수 없어서 보조기억장치를 이용해야 하는 경우.

- External Sort 알고리즘.
    1. 전체 데이터를 주기억장치에서 처리 가능한 크기인 n개의 블록으로 나눈다.
    2. 각각의 블록을 내부정렬을 통해서 정렬한다.
    3. 보조기억장치(입력)에 저장된 블록을 2개 선택.<br/>부분적으로 주기억 장치에 읽어 들여서 합병정렬을 수행하고, <br/> 합병된 결과를 또 다른 보조기억장치(출력)에 저장한다.
    4. 한번 입력쪽에 있는 보조기억장치의 블록개수가 0이 되면 입력과 출력 HDD의 역할을 바꿈.
    5. 블록이 1개가 될때까지 반복.

- External Sort의 시간복잡도 : <br/>
전체 데이터를 몇 번 처리하는가?<br/>
입력 크기가 N이고, 주기억장치의 메모리 크기가 M이라고 한다면,<br/>
한번 패스를 거칠 때 마다 블록의 크기가 2배씩 증가.<br/>
그러므로 k번 pass를 거치면 $2^kM = N$이 된다.<br/>
k는 패스 횟수이므로 k = $log_2{(N/M)}$이 되고, 시간복잡도이다.

- Tape Drive(TD)와 같이 한번 데이터를 읽으면 끝인 경우.
    1. 블록단위로 데이터를 읽을 때 2개의 보조 테이프 드라이브를 사용해서 번갈아 가며 저장한다.
    2. 출력 테이프 드라이브도 2개여야 합병한 후에도 번갈아 하며 저장함.
    3. 총 1개의 데이터 뭉치를 정렬하기 위해서는 4개의 테이프가 필요한것임.

- 다방향 합병. p-way 합병.
    1. 위의 TD 합병의 경우는 기본적으로 2-way 합병이다. (External도 2-way합병인듯.)
    2. 2-way TD 합병에서는 입력을 둘로 나누기 때문에 입력 TD 2개, 출력 TD 2개가 필요했다. 
    3. p-way 합병에서는 당연히 2p개가 필요하다.
    4. 입력을 주기억 장치의 크기로 블록을 나눈다.
    5. 나눈 블록들을 정렬하면서 p개의 보조기억장치에 넣는다.
    6. 블록을 p개씩 합병정렬하여 다른 보조기억장치에 저장.
    7. 이를 반복.

    - 시간복잡도는 $O(log_p{(N/M)})$으로 줄어들게 된다.

- 다단계 합병. Polyphase 합병.
    1. p-way 합병의 단점을 보완하기 위해(공간이 많이 필요.) p+1개의 보조기억장치만으로 p-way합병을 수행.
    2. 정렬된 크기가 M인 $F_n$개의 블록을 만듦.
    3. $F_n$은 피보나치 수이고, $F_n$보다 입력이 작다면 INT_MAX와 같은 수로 블록을 채움(쓰레기값)
    4. p = 2이고, 34개의 블록이 있을 때.
    5. 34 = 21 + 13.이므로 2개의 TD에 21개의 블록, 13개의 블록을 저장.
    6. 남은 하나의 블록에 다른 두 TD의 겹치는 수의 블록 (13개)를 합병정렬해서 2M의 크기를 갖는 블록 13개를 저장하고, 크기가 더 컸던 블록에는 남은 8개의 블록이 남음. 
    7. 위의 과정을 반복.
![06장 정렬알고리즘(기타)-2023 pdf - 프로필 1 - Microsoft​ Edge 2023-12-01 오후 5_24_37](https://github.com/wjdwocks/algorithm/assets/144427497/c239a0a5-4fcc-42c8-bff2-e244cd3910a1)

## 8장 근사 알고리즘.
- 근사 알고리즘이란?
    - NP-완전 문제들은 실 세계의 광범위한 영역에 활용되지만, 이 문제들을 다항식 시간에 해결할 수 있는 알고리즘은 발견되지 않았다.
    - 또한 다항식 시간 안에 해결할 수 없다고도 증명조차 하지 못했다.
    - NP-완전 문제들을 해결하기 위해서는 아레의 3가지 중에서 1가지는 포기해야 한다.
        1. 다항식 시간에 해를 찾기
        2. 모든 입력에 대해 해를 찾기
        3. 최적해를 찾는 것.
    - 근사 알고리즘은 NP-완전 문제를 해결하기 위해 3번을 포기한다. 
    - 최적해에 가까운 해를 찾기 위한 알고리즘이 근사 알고리즘이다.

- 근사해의 근사 비율
    - 근사 알고리즘은 다항식 시간 복잡도를 갖는 대신 근사해를 찾는다
    - 근사해가 얼마나 최적해와 가까운지를 나타내기 위해 근사 비율을 알아야한다.
    - 근사 비율을 계산하기 위해서는 최적해를 알아야 한다.  (모순 발생.)
    - 최적해를 대신할 수 있는 간접적인 최적해를 찾고, 이를 최적해로 삼아서 근사 비율을 계산한다.

### 1. 여행자 문제. (TSP Algorithm)
- 여행자가 임의의 한 도시에서 출발하여 다른 모든 도시를 1번씩만 방문하고 다시 출발했던 도시로 돌아오는 여행 경로의 길이를 최소화하는 문제.
- 여행자 문제의 조건 : <br/>
    1. 대칭성 : 도시 A에서 도시 B로 가는 거리는 도시 B에서 도시 A로 가는 거리와 같다.<br/>
    2. 삼각 부등식 특성 : 도시 A에서 도시 B로 가는 거리는 도시 A에서 다른 도시 C를 경유하여 도시 B로 가는 거리보다 짧다. (삼각 부등식 특성)
- TSP문제의 근사 알고리즘의 고안.
    1. 근사 알고리즘을 고안하려면 먼저 다항식 시간 알고리즘을 가지면서 유사한 특성을 가진 문제를 활용한다.
    2. TSP와 비슷한 특성을 가진 문제는 최소신장 트리 문제(MST)가 있다.
    3. MST의 모든 점을 연결하는 특성과 최소 가중치의 특성을 TSP에 응용하여 모든 도시를 트리 간선을 따라 1번씩 방문하도록 한다.

- TSP 근사 알고리즘
    1. 입력에 대해서 최소 신장 트리(MST)를 찾는다.
    2. 최소 신장 트리의 간선을 따라서 모든 도시를 방문하고 돌아오는 방문 순서를 찾는다.
    3. 삼각 부등식 특성에 의해 앞에서 한번 방문한 도시를 순서에서 제거한다.<br/>
    &rarr; 근사해.

- TSP의 MST를 이용한 근사 알고리즘의 시간복잡도.
    1. 크러스컬 알고리즘 : $O(mlogm)$, m은 간선의 개수.
    2. 프림 알고리즘 : $O(n^2)$, n은 점의 개수.
    3. 트리 간선을 따라서 도시 방문 순서를 찾는 데 걸리는 시간 : $+O(n)$, 트리의 간선 수가 (n-1)개 이므로.
    4. 사실 그냥 시점으로부터 간선을 따라 쭉 이동하면서 다음 간선없으면 돌아가고 이것만 하면됨.
    5. 정점의 중복을 제거 : $+O(n)$
    6. 총 시간복잡도 : $O(mlogm)$ or $O(n^2)$

- 근사 비율을 구하는 방법.
    1. 우리가 알고있는 최소신장 트리의 모든 간선 가중치의 합 = M 이라고 둠.
    2. 그러면 여행자 문제의 최적해의 총 가중치 OPT는 항상 M < OPT 이다.<br/>
    간선의 개수는 같고, 최소신장트리가 가장 짧기 때문.
    3. 위의 TSP 근사 알고리즘의 2번째에서 최소신장 트리를 통해서 모든 도시를 방문하고 돌아오는 경로의 총 길이는 2M이다. <br/>
    사이클이 형성되면 안되기 때문에 한번 방문하면 다시 돌아가야함.
    4. 그러므로 근사해의 총 가중치 OPT'는 항상 OPT' < 2M 이다.
    5. 그러므로 M < OPT < OPT' < 2M 이고, <br/>
    근사해의 값이 최적해의 값의 2배를 넘지 않는다.
    6. 근사 비율은 $2M / M = 2.0$

### 2. 정점 커버 문제.
- 정점 커버에 속한 점들로 그래프의 모든 간선을 '커버' 하는 문제.

- 정점 커버의 근사 알고리즘 : 집합 커버 문제.<br/>
정점 커버 문제의 입력 그래프를 집합 커버 문제의 입력으로 변환해서 SetCover 알고리즘의 해를 찾아 근사해로 사용한다.
    1. 정점 커버 알고리즘의 입력 : <br/>그래프의 정점과 그 정점들을 연결하는 간선들을 입력으로 받음.
    2. 집합 커버 알고리즘으로의 변환 : <br/>
    각 정점을 집합으로 두고, 그 정점에 연결된 간선들을 집합의 원소로 생각한다.
    3. 집합 커버 알고리즘을 이용한 근사 비율 : <br/>
    K ln n이라고 한다.(K는 상수, n은 정점의 개수.)

- 더 효율적인 정점 커버 알고리즘
    1. 점의 집합 커버 &rarr; 간선의 집합 커버로 생각한다.
    2. 선택된 간선의 양 끝점에 인접한 모든 간선들은 양 끝 점에 의해 커버됨.
    3. 가장 많은 간선을 커버할 수 있는 간선을 추가하다가, 모든 간선을 커버하게 되면 중단함.

- 간선의 집합 커버에서 극대 매칭.
    1. 매칭이란 : <br/>
    각 간선의 양점 끝점들이 중복되지 않는 간선의 집합. (선분들의 끝점이 각각 다른 선분들의 집합.)<br/> 정점이 간선에 중복해서 속하지 않음.
    2. 극대 매칭은 이미 선택된 간선에 기반을 두고 새로운 간선을 추가하려 해도 더 이상 추가할 수 없는 매칭을 말함.

- 간선의 집합 커버에서의 시간복잡도.
    1. 극대 매칭을 찾는 시간복잡도와 동일함.
    2. 극대 매칭을 찾기 위해 간선을 선택할 때.<br/>
    양 끝점이 이미 선택된 간선의 끝점인지를 검사.$O(n)$, n은 정점의 개수.
    3. 입력 그래프의 간선 수가 m이라면 각 간선에 대해서 2번의 과정을 반복.
    4. 시간 복잡도 : $O(nm)$

- 근사 비율 : 
    1. 극대 매칭을 '간접적인' 최적해로 사용.
    2. 매칭에 있는 간선의 수를 최적해의 값으로 사용.<br/> 어떠한 정점 커버라도 극대 매칭에 있는 간선을 커버해야 하기 때문에.<br/>
        - 이게 아마도 정점 커버 문제가 모든 간선을 커버해야 하는데, 그러려면 어차피 극대 매칭에 있는 모든 정점을 포함해야 한다.
        - 여기서는 간선을 추가했지만 이 간선은 양쪽 끝점을 포함하므로 우리는 간선당 2개의 점을 선택하게 된것임.
        - 그러므로 우리는 간선의 정점커버를 한 것이 2 * 정점의 정점커버를 한 것이다.
    3. 그러므로 근사 비율 = (극대 매칭의 각 간선의 양 끝점들의 수) / (극대 매칭의 간선의 수) = 2.0임

### 3. 통 채우기 문제.
- 통 용량이 C일 때 n개의 물건을 가장 적은 수의 통에 채우는 문제.

- 통 채우기 문제의 근사 알고리즘 : 그리디 알고리즘
    1. 최초 적합 : 첫 번째 통부터 차례로 살피며, 가장 먼제 여유가 있는 통에 넣는다.
    2. 다음 적합 : 직전에 물건을 넣은 통에 여유가 있으면 새 물건을 넣음.
    3. 최선 적합 : 기존의 통 중 새 물건이 들어가면 남는 부분이 가장 작은 통에 넣음.
    4. 최악 적합 : 기존의 통 중 새 물건이 들어가면 남는 부분이 가장 많은 통에 넣음.

- 시간 복잡도 : <br/>
최초, 최선, 최악 적합 : $O(n^2)$<br/>
다음 적합 : $O(n^2)$

- 최초, 최선, 최악 적합의 근사 비율
    1. 모든 물건을 담는 데 사용된 통의 수는 최적해에서 사용된 통의 수의 2배를 넘지 않는다.<br/> 각 알고리즘에 의하여 2개 이상의 통이 반 이하로 차있을 수 없다. <br/>
    새통을 사용하지 않고 거기에 채웠을 것이기 때문에.
    2. 최적해의 통의 수 : OPT라고 한다면<br/>
    $OPT >= \frac{(모든 물건의 크기의 합)}{C}$, C : 통의 크기.
    3. 각 방법이 사용한 통의 개수가 OPT'이라고 하면,<br/>
    OPT'의 통 중 기껏해야 1개의 통이 반 이하로 차 있으므로<br/> $(모든 물건의 크기의 합) > \frac{(OPT'-1)*C}{2}$ 가 된다.<br/>
    (우변이 OPT'-1개의 통을 반만 채웠을 경우이기 때문에.)
    4. $C*OPT >= (모든 물건의 크기의 합) >= \frac{C*(OPT'-1)}{2}$<br/>
    $2*OPT >= OPT'$이므로 근사 비율은 2.0이다.

- 다음 적합의 근사 비율.
    1. 다음 적합 알고리즘에 의해서 이웃한 두 통의 합은 무조건 통의 용량 C보다 크다.
    2. 모든 물건 크기의 합 > $\frac{OPT'}{2}*C$ <br/>
    &rarr; 이웃한 두통을 묶어서 보면 $\frac{OPT'}{2}$인데 묶인 각 통의 용량은 C보다 크기 때문이다.
    3. 그러므로  $\frac{모든 물건 크기의 합}{C}$ > $\frac{OPT'}{2}$
    4. 위에서 봤듯이 최적해의 통의 수 $OPT >= \frac{모든 물건 크기의 합}{C}$ 이므로 <br/>
    2 * OPT >= OPT' 이라서 근사 비율은 2.0.

### 4. 작업 스케줄링 문제.
- n개의 작업의 수행 시간 $t_i$, m개의 동일한 기계가 주어질 때 모든 작업이 가장 빨리 종료되도록 작업을 기계에 배정하는 문제.

- 작업 스케줄링 문제의 근사 알고리즘 : 그리디 알고리즘.
    - 현재까지 배정된 작업에 대해서 가장 빨리 끝나는 기계에 새 작업을 배정함.
    - pseudo-code
    ```cpp
    for j = 1 to m
        L[j] = 0
    for i = 1 to n
        min = 1
        for j = 2 to m
            if L[j] < L[min]
                min = j
        L[min] = L[min] + ti
    --------------------------------
    여기서 m은 기계의 개수, n은 작업의 개수.
    ti는 현재 작업을 수행하는 시간이다.
    첫 for문에서는 모든 기계의 종료시간을 0으로 초기화
    두번 째 for문에서는 작업을 하나하나 돌면서
    세번 째 for문에서 가장 일찍 끝나는 기계를 찾고
    그 기계에 작업 배정.
    ```
- 시간 복잡도 : <br/>
n개의 작업을 배정하고, 각 작업 당 m개의 기계를 비교하므로 $O(nm)$이다.

- 근사 비율 : 
    1. 가장 마지막으로 배정된 작업 i가 T 부터 수행되고 끝나는 시간이 OPT' = T + $t_i$라고 한다.
    2. T'은 작업 i를 제외한 모든 작업의 수행 시간의 합을 기계의 수 m으로 나눈 값.
    3. 그러면 T <= T'이다.
    4. OPT' = T + $t_i$ <= $t_i$ + T'<br/>
    = $t_i$ + $\frac{(\sum^n_{j=1}t_j) - t_i}{m}$
    // $T' = \frac{(\sum^n_{j=1}t_j)-t_i}{m}$이기 때문. T'이 $t_i$를 제외한 모든 작업의 평균 시간이라서.
    <br/>
    = $t_i$ + $\frac{(\sum^n_{j=1}t_j)}{m} - \frac{t_i}{m}$<br/>
    = $\frac{1}{m}\sum^n_{j=1}t_j + (1-\frac{1}{m})t_i$ // $\frac{1}{m}\sum^n_{j=1}t_j$ 얘가 OPT보다 작고, $t_i$도 OPT보다는 훨씬 작다. <br/> 
    <= OPT + $(1-\frac{1}{m})$ OPT<br/>
    = (2-$\frac{1}{m}$)OPT<br/>
    <= 2OPT

## 5. 클러스터링 문제.
- n개의 점을 k개의 그룹으로 나누고 각 그룹의 중심이 되는 k개의 점을 선택하는 문제.<br/>
단, 가장 큰 반경을 가진 그룹의 직경이 최소가 되로록 k개의 점을 선택하는게 최적해.

- 클러스터링 문제를 해결하기 위한 근사 알고리즘 : 그리디 알고리즘.
    1. 첫번 째 센터 점은 임의로 선택한다.
    2. 두번 째 센터 점은 첫번째 점과 가장 먼 점을 선택한다.
    3. n번 째 센터 점은 1 ~ n-1번째 센터점들 사이의 최솟값 중 가장 큰 값을 선택한다.

- 그리디 알고리즘을 이용한 클러스터링 문제의 근사 알고리즘 pseudo-code
```cpp
for j = 2 to k
    for i = i to n-1
        if x_i != 센터 // 센터는 이미 선택된 점.
            각 센터까지의 거리를 계산하고, 가장 가까운 센터까지의 거리를
            D[i]에 저장함.
    D[i]들 중 최댓값을 다음 센터로 정함.

각 센터가 아닌 점들로부터 센터까지의 거리를 확인하며 
자신이 속한 그룹을 찾음.
```
![이해성 2023-12-02 오후 11_41_30](https://github.com/wjdwocks/algorithm/assets/144427497/d4cbdc7b-6d70-4289-a9e6-36a102616f63)

- 그룹으로 나누는 방법
    1. 센터가 아닌 점$x_i$는 각 센터까지의 거리를 확인한 뒤 가장 가까운 센터의 그룹에 포함된다.

- 시간 복잡도 : 
    1. 가장 외부의 for문 : k-1개의 센터에 대해 반복. : O(k)
    2. 내부 for문 : n개의 점에 대해서 k번 센터까지의 거리를 확인 : O(kn)
    3. 선터까지의 거리 중 최댓값을 찾음 : O(n)
    4. 반복문이 모두 끝난 뒤 각 점과 센터의 점들 까지의 거리르 비교하며 자신이 속한 그룹을 찾음. : O(kn).
    5. 총 시간복잡도 : (k-1)x(O(kn)+O(n)) + O(kn) = $O(k^2n)$

- 근사 비율 : 
    1. 최적해가 만든 그룹 중 가장 큰 직경을 OPT라고 한다.
    2. OPT의 하한을 간접적으로 찾기 위해 센터를 1개 더 찾은 경우를 생각함.
    3. 추가한 센터와 가장 가까운 센터인 점까지의 거리를 d라고 한다.
    4. 추가한 센터는 원래는 어떤 센터의 그룹에 속해있었을 것이다.
    5. 그렇다면 OPT는 무조건 d보다는 크다.
    6. OPT >= d이다.
    7. OPT' <= 2d 이다. // 당연히 2d보다는 작다. <br/>그렇게 된다면 다음 센터가 다른 곳에 생겼을 것이기 때문에.
    8. 그래서 2.0 ?? 좀 x같이 설명해놨네

![08장 근사알고리즘-2023-v1 pdf 외 페이지 1개 - 프로필 1 - Microsoft​ Edge 2023-12-02 오후 11_46_42](https://github.com/wjdwocks/algorithm/assets/144427497/f0bb1c20-8e47-4507-b253-54c9d295f595)


## 7장 NP-완전 문제
- NP-완전 이론 : 문제를 현실적인 시간(다항식 시간복잡도)에 풀 수 있는가에 관한 이론.

- 문제의 종류
    1. 풀 수 없는 문제들. : 다루기 힘들다고 증명된 문제.
    2. 풀 수 있는 문제들. 
        - NP 문제 : 다루기 힘들다고 증명되지 않았고, 다항시간 알고리즘도 발견하지 못한 문제.
        - P 문제 : 다항시간 알고리즘을 찾은 문제.

- 문제를 **다루기 힘든 정도**에 따라서 문제의 종류를 구분할 수 있다.
    1. P(polynomial) 문제 : 다항식 시간 알고리즘을 가진 문제.
    2. NP(Non-**deterministic** Polynomial) 문제 : **비결정적 다항식 시간** 알고리즘을 가진 문제.<br/>
    아직 다항식 시간 내에 해결할 수 있다고 밝혀지지 않은.
    3. NP-Complete 문제 : NP 문제들 중 NP-hard인 문제.
    4. NP-hard 문제 : 모든 NP문제를 다항식 시간 안에 A로 변환(환원)이 가능할 때 그 문제 A를 지칭하는 말.

- 최적화 문제와 결정 문제의 차이를 이해하자.
    - 최적화 문제 : 최적의 해를 찾는 문제.
    - 결정 문제 : 어떤 기준을 정해주고 특정 해가 이 기준을 만족하는지 확인하는 문제.
    - 어떤 문제의 최적화 문제의 다항 알고리즘이 있다면, 그 알고리즘을 통해 다항 시간의 결정문제 알고리즘도 쉽게 만들 수 있다.
    - 반대로 결정 문제 알고리즘이 있다면, 추측한 값을 여러번 바꿔가며 최적화 문제의 해도 구할 수 있다.

- NP-complete(완전) 문제를 이해해야 함.
    - NP-완전 증명 방법을 이해한다.
    - NP 집합에 속하는 결정 문제 중에서 가장 어려운 문제의 부분집합.
    - NP-완전이라는 사실이 판명됨으로써 얻을 수 있는 이득이 무엇인가?
        - 이 문제가 아무도 풀지 못한 어려운 문제의 집단에 속한다는 것을 증명하는 것임.

- 결정문제적 관점에서의 NP문제 
    1. 최적화 알고리즘은 다항식 시간 내에 해결할 수 있는지 모르지만,<br/> 검산은 다항식 시간 내에 해결할 수 있는 문제
    2. 모든 P문제는 NP문제에 속함.
    3. P문제 집합과 NP-Complete 문제집합을 모두 포함하는 집합.
    4. 그렇기 때문에 어떤 문제가 있고, 최적화 알고리즘이 정해져 있지 않은 상태에서 힌트로 주어진 해가 Yes인지, No인지 다항식 시간 내에 정해줄 수 있다면 이 문제는 NP문제인 것은 확실하지만 P문제인 것은 아직 모르는 것이다.

- NP - complete문제란?
    - NP 집합에 속하는 결정 문제 중 가장 어려운 문제의 부분집합.
    - 지금까지는 다항식 시간에 풀기 어렵다고 판단되면서 서로 밀접한 논리 관계를 가진 문제 집합.

- P와 NP문제의 분류.
    1. 어떤 문제가 다항 알고리즘이 있는 경우. -> P문제.
    2. 다항 알고리즘을 찾지 못한 경우 -> NP문제.
    3. 알려진 NP-완전 문제로 환원/변환 하여 풀 수 있는 경우 -> NP - P에 속하는 문제이다.(P바깥)
    4. 문제 A와 B가 관련이 있다면 서로의 입력으로 문제를 변환/환원하여 문제를 해결할 수 있다.

1. 여행자 문제에서의 NP 구분.
    - 최적화 문제 : 각 도시를 1번씩만 방문하고 시작 도시로 돌아오는 전체 경로 중 가장 짧은 순서.
    - 결정 문제로 변환 : 각 도시를 1번씩만 방문하고 시작 도시로 돌아오는 경로 중 K보다 짧은 경로가 존재하는가?
    - 하나의 해를 추측함 그 해의 총 거리를 계산해서 K보다 작으면 yes, 아니라면 No로 대답을 다항시간 내에 할 수 있으므로 NP문제이다.

2. NP-완전 문제의 특성. (환원/변환)
    - 어떤 문제 A가 어렵다. (다항 알고리즘이 없다)
    - 하지만, 문제 A를 알려진 NP-complete로 환원하여 해결할 수 있다면, 이 문제 A또한 NP-complete문제이다.
    - 이에 대한 예시로는 subset Sum문제가 있다.
        - 정수의 집합 S에 대해 부분 집합들 중에서 원소의 합이 K가 되는 부분집합을 찾는 문제.
        - 이 문제는 분할문제로 환원하여 해결할 수 있다.
        - S = {20, 35, 45, 70, 80}이었다면 S' = S + {t}를 새로 만든다.
        - t = S - 2K이고, 이제 알려진 분할 알고리즘으로 S'의 해를 구한다. (위의 예시에선 t = 40이다.)
        - 그러면 분할된 두 집합은 각각 145의 값을 가진다.
        - 거기에 t가 있던 집합에서 t를 빼주면 그 집합의 원소합은 105가 나옴. 해결완
    - 위의 subset Sum문제와 같이 NP-complete문제들은 서로 엮여있어서 한 NP-complete문제가 다항 문제로 풀리게 되면, 모든 다른 문제들도 다항시간문제로 풀리게 된다.

3. NP-하드 문제란?
    - 어떤 문제 A에 대해서 모든 NP문제가 A로의 변환을 통해 다항 알고리즘을 가질 수 있게 한다.
    - NP-하드 문제는 반드시 NP문제일 필요는 없다(다항 시간 검증은 필수가 아니다.)

4. 다시 문제의 분류를 적어보자.
    1. P문제 : 다항 시간내에 해결할 수 있는 최적화 알고리즘이 있는 문제.
    2. NP문제 : 다항 시간 내에 해결할 수 있는 최적화 알고리즘이 있는지는 확실하지 않지만, 다항 시간 내에 추측해를 검증할 수 있는 문제.
    3. NP-hard 문제 : 어떤 문제 A를 통하여 모든 NP문제를 다항 시간 내에 해결할 수 있게 해주는 문제.
    4. NP-complete 문제 : 다항 시간 내에 추측해를 검증할 수 있고, 하나의 np-complete문제가 해결된다면 다른 np-complete문제들도 환원을 통해 다항 시간에 해결될 수 있게 한다.
